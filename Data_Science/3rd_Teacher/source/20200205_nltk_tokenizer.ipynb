{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'think and wonder. wonder and think.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'\\w+') # 단어로 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think', 'and', 'wonder', 'wonder', 'and', 'think']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think', 'and', 'wonder', 'wonder', 'and', 'think', '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('\\W+',sent) # 특수문자/화이트스페이스로 구분하여 단어 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0    So there is no way for me to plug it in here i...  0\n",
       "1                          Good case, Excellent value.  1\n",
       "2                               Great for the jawbone.  1\n",
       "3    Tied to charger for conversations lasting more...  0\n",
       "4                                    The mic is great.  1\n",
       "..                                                 ... ..\n",
       "995  The screen does get smudged easily because it ...  0\n",
       "996  What a piece of junk.. I lose more calls on th...  0\n",
       "997                       Item Does Not Match Picture.  0\n",
       "998  The only thing that disappoint me is the infra...  0\n",
       "999  You can not answer calls with the unit, never ...  0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = pd.read_csv('../data/amazon_cells_labelled.txt',\n",
    "                     sep=r'\\t',\n",
    "                     header=None)\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label\n",
       "0    So there is no way for me to plug it in here i...      0\n",
       "1                          Good case, Excellent value.      1\n",
       "2                               Great for the jawbone.      1\n",
       "3    Tied to charger for conversations lasting more...      0\n",
       "4                                    The mic is great.      1\n",
       "..                                                 ...    ...\n",
       "995  The screen does get smudged easily because it ...      0\n",
       "996  What a piece of junk.. I lose more calls on th...      0\n",
       "997                       Item Does Not Match Picture.      0\n",
       "998  The only thing that disappoint me is the infra...      0\n",
       "999  You can not answer calls with the unit, never ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.columns = ['sentence','label']\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = amazon.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1658 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4909 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'\\w+') # r'[a-zA-Z0-9]'\n",
    "\n",
    "cv = CountVectorizer(analyzer='word',\n",
    "                     ngram_range=(1,1),\n",
    "                     lowercase=True,\n",
    "                     stop_words='english',\n",
    "                     tokenizer=token.tokenize)\n",
    "\n",
    "sent = cv.fit_transform(sent)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '15',\n",
       " '15g',\n",
       " '18',\n",
       " '2',\n",
       " '20',\n",
       " '2000',\n",
       " '2005',\n",
       " '2160',\n",
       " '24',\n",
       " '2mp',\n",
       " '3',\n",
       " '325',\n",
       " '350',\n",
       " '375',\n",
       " '3o',\n",
       " '4',\n",
       " '42',\n",
       " '44',\n",
       " '45',\n",
       " '4s',\n",
       " '5',\n",
       " '50',\n",
       " '5020',\n",
       " '510',\n",
       " '5320',\n",
       " '6',\n",
       " '680',\n",
       " '7',\n",
       " '700w',\n",
       " '8',\n",
       " '8125',\n",
       " '8525',\n",
       " '8530',\n",
       " 'abhor',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abound',\n",
       " 'absolutel',\n",
       " 'absolutely',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accessable',\n",
       " 'accessing',\n",
       " 'accessory',\n",
       " 'accessoryone',\n",
       " 'accidentally',\n",
       " 'accompanied',\n",
       " 'according',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activesync',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'add',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adhesive',\n",
       " 'adorable',\n",
       " 'advertised',\n",
       " 'advise',\n",
       " 'aggravating',\n",
       " 'ago',\n",
       " 'alarm',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alot',\n",
       " 'aluminum',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antena',\n",
       " 'anti',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apparently',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'applifies',\n",
       " 'appointments',\n",
       " 'area',\n",
       " 'arguing',\n",
       " 'armband',\n",
       " 'arrival',\n",
       " 'arrived',\n",
       " 'asia',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'assumed',\n",
       " 'atleast',\n",
       " 'att',\n",
       " 'attacked',\n",
       " 'attractive',\n",
       " 'audio',\n",
       " 'authentic',\n",
       " 'auto',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'avoiding',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awkward',\n",
       " 'awsome',\n",
       " 'background',\n",
       " 'backlight',\n",
       " 'bad',\n",
       " 'balance',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bars',\n",
       " 'basement',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " 'beat',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'bed',\n",
       " 'beep',\n",
       " 'beeping',\n",
       " 'behing',\n",
       " 'believe',\n",
       " 'bells',\n",
       " 'belt',\n",
       " 'bend',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beware',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bills',\n",
       " 'bit',\n",
       " 'bitpim',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blacktop',\n",
       " 'bland',\n",
       " 'blew',\n",
       " 'blue',\n",
       " 'blueant',\n",
       " 'bluetoooth',\n",
       " 'bluetooth',\n",
       " 'bluetooths',\n",
       " 'bmw',\n",
       " 'book',\n",
       " 'booking',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'bose',\n",
       " 'bother',\n",
       " 'bottowm',\n",
       " 'bought',\n",
       " 'bougth',\n",
       " 'boy',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'breakage',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'brilliant',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'browser',\n",
       " 'browsing',\n",
       " 'bt',\n",
       " 'bt250v',\n",
       " 'bt50',\n",
       " 'bubbling',\n",
       " 'bucks',\n",
       " 'buds',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulky',\n",
       " 'bumpers',\n",
       " 'button',\n",
       " 'buttons',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buying',\n",
       " 'buyit',\n",
       " 'buzzing',\n",
       " 'ca',\n",
       " 'cable',\n",
       " 'cables',\n",
       " 'calendar',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'canal',\n",
       " 'cancellation',\n",
       " 'cancelling',\n",
       " 'capability',\n",
       " 'capacity',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'carried',\n",
       " 'carriers',\n",
       " 'carries',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'casing',\n",
       " 'cassette',\n",
       " 'cat',\n",
       " 'catching',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cbr',\n",
       " 'cds',\n",
       " 'cell',\n",
       " 'cellphone',\n",
       " 'cellphones',\n",
       " 'cellular',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charger',\n",
       " 'chargers',\n",
       " 'charges',\n",
       " 'charging',\n",
       " 'charm',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheaply',\n",
       " 'cheapy',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'child',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'christmas',\n",
       " 'cingulair',\n",
       " 'cingular',\n",
       " 'clarity',\n",
       " 'classy',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'clicks',\n",
       " 'clip',\n",
       " 'clipping',\n",
       " 'clips',\n",
       " 'clock',\n",
       " 'colleague',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'colors',\n",
       " 'combination',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comfortible',\n",
       " 'coming',\n",
       " 'comments',\n",
       " 'commercials',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'commuter',\n",
       " 'company',\n",
       " 'comparably',\n",
       " 'compared',\n",
       " 'compete',\n",
       " 'competitors',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaint',\n",
       " 'complaints',\n",
       " 'completely',\n",
       " 'compliments',\n",
       " 'compromise',\n",
       " 'computer',\n",
       " 'concrete',\n",
       " 'conditions',\n",
       " 'confortable',\n",
       " 'confusing',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'constantly',\n",
       " 'constructed',\n",
       " 'construction',\n",
       " 'consumer',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'contacting',\n",
       " 'contacts',\n",
       " 'continue',\n",
       " 'continues',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'controls',\n",
       " 'contstruct',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'converter',\n",
       " 'cool',\n",
       " 'copier',\n",
       " 'copy',\n",
       " 'corded',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'couldn',\n",
       " 'counter',\n",
       " 'counterfeit',\n",
       " 'couple',\n",
       " 'coupon',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'crack',\n",
       " 'cracked',\n",
       " 'cradle',\n",
       " 'cradles',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'crashed',\n",
       " 'crawl',\n",
       " 'creaks',\n",
       " 'crisp',\n",
       " 'cumbersome',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutouts',\n",
       " 'cuts',\n",
       " 'd',\n",
       " 'd807',\n",
       " 'damage',\n",
       " 'darn',\n",
       " 'data',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deaf',\n",
       " 'deal',\n",
       " 'decade',\n",
       " 'decent',\n",
       " 'decision',\n",
       " 'defeats',\n",
       " 'defect',\n",
       " 'defective',\n",
       " 'deffinitely',\n",
       " 'definitely',\n",
       " 'definitly',\n",
       " 'delay',\n",
       " 'delivery',\n",
       " 'described',\n",
       " 'description',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'designs',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'destroying',\n",
       " 'detachable',\n",
       " 'detailed',\n",
       " 'development',\n",
       " 'device',\n",
       " 'devices',\n",
       " 'dialing',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'dieing',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'directed',\n",
       " 'directions',\n",
       " 'directly',\n",
       " 'dirty',\n",
       " 'disapoinment',\n",
       " 'disapointing',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'discarded',\n",
       " 'discomfort',\n",
       " 'disconnected',\n",
       " 'discount',\n",
       " 'disgusting',\n",
       " 'display',\n",
       " 'displeased',\n",
       " 'disposable',\n",
       " 'dissapointed',\n",
       " 'dissapointing',\n",
       " 'distorted',\n",
       " 'distracting',\n",
       " 'dit',\n",
       " 'division',\n",
       " 'dna',\n",
       " 'docking',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'download',\n",
       " 'downloading',\n",
       " 'dozen',\n",
       " 'dozens',\n",
       " 'drain',\n",
       " 'drained',\n",
       " 'drains',\n",
       " 'drawback',\n",
       " 'driving',\n",
       " 'drivng',\n",
       " 'droid',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'dropping',\n",
       " 'drops',\n",
       " 'dual',\n",
       " 'durable',\n",
       " 'dustpan',\n",
       " 'dying',\n",
       " 'e',\n",
       " 'e2',\n",
       " 'e715',\n",
       " 'ear',\n",
       " 'earbud',\n",
       " 'earbuds',\n",
       " 'earbugs',\n",
       " 'eargels',\n",
       " 'earlier',\n",
       " 'earpad',\n",
       " 'earphone',\n",
       " 'earphones',\n",
       " 'earpiece',\n",
       " 'earpieces',\n",
       " 'ears',\n",
       " 'earset',\n",
       " 'ease',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'echo',\n",
       " 'edge',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'electronics',\n",
       " 'elegant',\n",
       " 'embarassing',\n",
       " 'embarrassing',\n",
       " 'embedded',\n",
       " 'encourage',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ends',\n",
       " 'engineered',\n",
       " 'enjoy',\n",
       " 'enter',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'env',\n",
       " 'equipment',\n",
       " 'era',\n",
       " 'ergonomic',\n",
       " 'ericson',\n",
       " 'ericsson',\n",
       " 'especially',\n",
       " 'essentially',\n",
       " 'europe',\n",
       " 'eventually',\n",
       " 'everyday',\n",
       " 'exactly',\n",
       " 'exceeds',\n",
       " 'excelent',\n",
       " 'excellent',\n",
       " 'excels',\n",
       " 'exceptional',\n",
       " 'excessive',\n",
       " 'exchange',\n",
       " 'exchanged',\n",
       " 'excited',\n",
       " 'exclaim',\n",
       " 'excrutiatingly',\n",
       " 'exercise',\n",
       " 'existing',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'explain',\n",
       " 'extended',\n",
       " 'exterior',\n",
       " 'external',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'faceplates',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'fairly',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'father',\n",
       " 'favorite',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'fee',\n",
       " 'feel',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'felt',\n",
       " 'fi',\n",
       " 'figure',\n",
       " 'file',\n",
       " 'finally',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finished',\n",
       " 'fit',\n",
       " 'fits',\n",
       " 'fixes',\n",
       " 'flash',\n",
       " 'flaw',\n",
       " 'flawed',\n",
       " 'flawless',\n",
       " 'flawlessly',\n",
       " 'flaws',\n",
       " 'flimsy',\n",
       " 'flip',\n",
       " 'flipphones',\n",
       " 'fliptop',\n",
       " 'floor',\n",
       " 'floppy',\n",
       " 'flops',\n",
       " 'flush',\n",
       " 'fm',\n",
       " 'followed',\n",
       " 'fond',\n",
       " 'fooled',\n",
       " 'forced',\n",
       " 'forever',\n",
       " 'forgeries',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'fourth',\n",
       " 'fraction',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freeway',\n",
       " 'freezes',\n",
       " 'frequently4',\n",
       " 'frequentyly',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'frog',\n",
       " 'frustration',\n",
       " 'fry',\n",
       " 'ft',\n",
       " 'fulfills',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'functionality',\n",
       " 'functions',\n",
       " 'funny',\n",
       " 'gadget',\n",
       " 'gadgets',\n",
       " 'games',\n",
       " 'garbage',\n",
       " 'garbled',\n",
       " 'gave',\n",
       " 'geeky',\n",
       " 'gels',\n",
       " 'generally',\n",
       " 'gentle',\n",
       " 'genuine',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'gimmick',\n",
       " 'girl',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glare',\n",
       " 'glasses',\n",
       " 'glove',\n",
       " 'glued',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'good7',\n",
       " 'gosh',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'graphics',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'grey',\n",
       " 'grip',\n",
       " 'grtting',\n",
       " 'guess',\n",
       " 'gx2',\n",
       " 'h500',\n",
       " 'hair',\n",
       " 'hand',\n",
       " 'handheld',\n",
       " 'hands',\n",
       " 'handset',\n",
       " 'handsfree',\n",
       " 'handy',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happier',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'hated',\n",
       " 'haul',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'headbands',\n",
       " 'headphones',\n",
       " 'headset',\n",
       " 'headsets',\n",
       " 'hear',\n",
       " 'hearing',\n",
       " 'heavy',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'high',\n",
       " 'highest',\n",
       " 'highly',\n",
       " 'highy',\n",
       " 'hinge',\n",
       " 'hit',\n",
       " 'hitch',\n",
       " 'hold',\n",
       " 'holder',\n",
       " 'holding',\n",
       " 'holds',\n",
       " 'holster',\n",
       " 'home',\n",
       " 'hook',\n",
       " 'hoped',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'hoursthe',\n",
       " 'house',\n",
       " 'hs850',\n",
       " 'huge',\n",
       " 'humans',\n",
       " 'humming',\n",
       " 'hurt',\n",
       " 'hybrid',\n",
       " 'hype',\n",
       " 'iam',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'igo',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'imac',\n",
       " 'images',\n",
       " 'imagine',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'impressive',\n",
       " 'improper',\n",
       " 'improve',\n",
       " 'improvement',\n",
       " 'inches',\n",
       " 'included',\n",
       " 'incoming',\n",
       " 'inconspicuous',\n",
       " 'increase',\n",
       " 'incrediable',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indoors',\n",
       " 'industrial',\n",
       " 'inexcusable',\n",
       " 'inexpensive',\n",
       " 'infatuated',\n",
       " 'inform',\n",
       " 'infra',\n",
       " 'infuriating',\n",
       " 'insert',\n",
       " 'inside',\n",
       " 'install',\n",
       " 'installed',\n",
       " 'instance',\n",
       " 'instead',\n",
       " 'instruction',\n",
       " 'instructions',\n",
       " 'integrated',\n",
       " 'intended',\n",
       " 'interested',\n",
       " 'interface',\n",
       " 'intermittently',\n",
       " 'internet',\n",
       " 'invented',\n",
       " 'investment',\n",
       " 'iphone',\n",
       " 'ipod',\n",
       " 'ipods',\n",
       " 'ir',\n",
       " 'irda',\n",
       " 'iriver',\n",
       " 'isn',\n",
       " 'issues',\n",
       " 'item',\n",
       " 'items',\n",
       " 'jabra',\n",
       " 'jabra350',\n",
       " 'jack',\n",
       " 'jawbone',\n",
       " 'jerks',\n",
       " 'jiggle',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'joy',\n",
       " 'juice',\n",
       " 'junk',\n",
       " 'just',\n",
       " 'jx',\n",
       " 'keen',\n",
       " 'keeping',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'keyboard',\n",
       " 'keypad',\n",
       " 'keypads',\n",
       " 'keys',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'kindle',\n",
       " 'kitchen',\n",
       " 'kits',\n",
       " 'knock',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'krussel',\n",
       " 'l7c',\n",
       " 'lacking',\n",
       " 'land',\n",
       " 'lap',\n",
       " 'laptop',\n",
       " 'large',\n",
       " 'lasted',\n",
       " 'lasting',\n",
       " 'lasts',\n",
       " 'latch',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'laughing',\n",
       " 'leaf',\n",
       " 'leaks',\n",
       " 'learned',\n",
       " 'leather',\n",
       " 'left',\n",
       " 'lense',\n",
       " 'leopard',\n",
       " 'lesson',\n",
       " 'let',\n",
       " 'letting',\n",
       " 'lg',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lightly',\n",
       " 'lights',\n",
       " 'lightweight',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likes',\n",
       " 'line',\n",
       " 'linked',\n",
       " 'linking',\n",
       " 'linksys',\n",
       " 'listener',\n",
       " 'listening',\n",
       " 'lit',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'living',\n",
       " 'll',\n",
       " 'loads',\n",
       " 'lock',\n",
       " 'locked',\n",
       " 'locks',\n",
       " 'logitech',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'loop',\n",
       " 'loops',\n",
       " 'loose',\n",
       " 'looses',\n",
       " 'los',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'loud',\n",
       " 'louder',\n",
       " 'loudest',\n",
       " 'loudspeaker',\n",
       " 'lousy',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'loves',\n",
       " 'low',\n",
       " 'luck',\n",
       " 'm',\n",
       " 'machine',\n",
       " 'magical',\n",
       " 'magnetic',\n",
       " 'mail',\n",
       " 'mainly',\n",
       " 'maintain',\n",
       " 'maintains',\n",
       " 'major',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'managed',\n",
       " 'management',\n",
       " 'manual',\n",
       " 'manufacturer',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'match',\n",
       " 'material',\n",
       " 'max',\n",
       " 'means',\n",
       " 'mechanism',\n",
       " 'media',\n",
       " 'mediocre',\n",
       " 'mega',\n",
       " 'megapixels',\n",
       " 'memory',\n",
       " 'mention',\n",
       " 'mentioned',\n",
       " 'menus',\n",
       " 'mere',\n",
       " 'mess',\n",
       " 'message',\n",
       " 'messages',\n",
       " 'messaging',\n",
       " 'messes',\n",
       " 'metal',\n",
       " 'metro',\n",
       " 'mic',\n",
       " 'microphone',\n",
       " 'microsoft',\n",
       " 'mind',\n",
       " 'mini',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'misleading',\n",
       " 'missed',\n",
       " 'mistake',\n",
       " 'mobile',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'modest',\n",
       " 'money',\n",
       " 'monkeys',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'mother',\n",
       " 'moto',\n",
       " 'motor',\n",
       " 'motorola',\n",
       " 'motorolas',\n",
       " 'moving',\n",
       " 'mp3',\n",
       " 'mp3s',\n",
       " 'muddy',\n",
       " 'muffled',\n",
       " 'multiple',\n",
       " 'music',\n",
       " 'mute',\n",
       " 'nano',\n",
       " 'navigate',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'neat',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needless',\n",
       " 'needs',\n",
       " 'negatively',\n",
       " 'network',\n",
       " 'new',\n",
       " 'ngage',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'nicer',\n",
       " 'night',\n",
       " 'nightmare',\n",
       " 'noise',\n",
       " 'noises',\n",
       " 'nokia',\n",
       " 'normal',\n",
       " 'normally',\n",
       " 'note',\n",
       " 'noted',\n",
       " 'notice',\n",
       " 'noticed',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'numerous',\n",
       " 'nyc',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'occupied',\n",
       " 'odd',\n",
       " 'oem',\n",
       " 'offering',\n",
       " 'offers',\n",
       " 'official',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "x = {\n",
    "    'name':'john',\n",
    "    'age':30,\n",
    "    'city':'new york'\n",
    "}\n",
    "x['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"john\", \"age\": 30, \"city\": \"new york\"}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_json = json.dumps(x)\n",
    "x_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'john', 'age': 30, 'city': 'new york'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(x_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random number example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "rand = random.randint(3,9)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting = ['hi','hello','how are you ?']\n",
    "greeting[random.randint(0,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'hi']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(greeting, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 16, 18, 20, 30, 42]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(random.sample(range(1,46),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703047569388938"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.094190113808374"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(20,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting = ['Hi there', \n",
    "            'How are you',\n",
    "            'Is anyone there?', \n",
    "            'Hey', \n",
    "            'Hola', \n",
    "            'Hello', \n",
    "            'Good day'] #label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_response = ['Hello, thanks for asking', \n",
    "                     'Good to see you again',\n",
    "                     'Hi there, how can I help?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbye = ['Bye', \n",
    "           'See you later', \n",
    "           'Goodbye', \n",
    "           'Nice chatting to you, bye',\n",
    "           'Till next time'] #label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodbye_response = ['See you!', \n",
    "                    'Have a nice day', \n",
    "                    'Bye! come back again soon.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "thanks = ['Thanks', \n",
    "          'Thank you', \n",
    "          'That is helpful', \n",
    "          'Awsome, thanks', \n",
    "          'Thank you for helping me'] #label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "thanks_response = ['Happy to help!', \n",
    "                   'Any time!', \n",
    "                   'My pleasure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dial = greeting + goodbye + thanks\n",
    "len(first_dial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array([0]*len(greeting)+[1]*len(goodbye)+[2]*len(thanks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hi there</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>How are you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Hey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Good day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>See you later</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Goodbye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Nice chatting to you, bye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Till next time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>That is helpful</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Awsome, thanks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Thank you for helping me</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentence  label\n",
       "0                    Hi there      0\n",
       "1                 How are you      0\n",
       "2            Is anyone there?      0\n",
       "3                         Hey      0\n",
       "4                        Hola      0\n",
       "5                       Hello      0\n",
       "6                    Good day      0\n",
       "7                         Bye      1\n",
       "8               See you later      1\n",
       "9                     Goodbye      1\n",
       "10  Nice chatting to you, bye      1\n",
       "11             Till next time      1\n",
       "12                     Thanks      2\n",
       "13                  Thank you      2\n",
       "14            That is helpful      2\n",
       "15             Awsome, thanks      2\n",
       "16   Thank you for helping me      2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sentence':first_dial,\n",
    "                   'label':label})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "len(word_tokenize(' '.join(first_dial)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[34, 41],\n",
       " [23, 17, 37],\n",
       " [5, 4, 41],\n",
       " [10],\n",
       " [8],\n",
       " [40],\n",
       " [10, 37],\n",
       " [19],\n",
       " [11, 37, 16],\n",
       " [39],\n",
       " [14, 1, 12, 37, 19],\n",
       " [28, 22, 19],\n",
       " [40],\n",
       " [25, 37],\n",
       " [23, 5, 11],\n",
       " [30, 40],\n",
       " [25, 37, 36, 17, 23]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "vocab_size = 42\n",
    "encoded_sent = [one_hot(s, vocab_size) for s in df.sentence]\n",
    "encoded_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 5\n",
    "padded_sent = pad_sequences(encoded_sent, \n",
    "                            maxlen=5, \n",
    "                            padding='post')\n",
    "padded_sent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 13 samples, validate on 4 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sundooedu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 1.1110 - acc: 0.1538 - val_loss: 1.0637 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 608us/step - loss: 1.1076 - acc: 0.1538 - val_loss: 1.0680 - val_acc: 0.7500\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 307us/step - loss: 1.1045 - acc: 0.1538 - val_loss: 1.0723 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 304us/step - loss: 1.1015 - acc: 0.0769 - val_loss: 1.0763 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 307us/step - loss: 1.0991 - acc: 0.0769 - val_loss: 1.0799 - val_acc: 0.2500\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 229us/step - loss: 1.0970 - acc: 0.0769 - val_loss: 1.0834 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0953 - acc: 0.0769 - val_loss: 1.0867 - val_acc: 0.2500\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0938 - acc: 0.1538 - val_loss: 1.0898 - val_acc: 0.2500\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 227us/step - loss: 1.0923 - acc: 0.2308 - val_loss: 1.0926 - val_acc: 0.2500\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0912 - acc: 0.2308 - val_loss: 1.0952 - val_acc: 0.2500\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 151us/step - loss: 1.0901 - acc: 0.3077 - val_loss: 1.0977 - val_acc: 0.2500\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0890 - acc: 0.3077 - val_loss: 1.1000 - val_acc: 0.2500\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0880 - acc: 0.3846 - val_loss: 1.1018 - val_acc: 0.2500\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0870 - acc: 0.3846 - val_loss: 1.1036 - val_acc: 0.2500\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0859 - acc: 0.3846 - val_loss: 1.1053 - val_acc: 0.2500\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0848 - acc: 0.3846 - val_loss: 1.1070 - val_acc: 0.2500\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0837 - acc: 0.3846 - val_loss: 1.1086 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 307us/step - loss: 1.0825 - acc: 0.3846 - val_loss: 1.1100 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0814 - acc: 0.3846 - val_loss: 1.1114 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 151us/step - loss: 1.0802 - acc: 0.3846 - val_loss: 1.1128 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0789 - acc: 0.3846 - val_loss: 1.1141 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0777 - acc: 0.6923 - val_loss: 1.1153 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 458us/step - loss: 1.0764 - acc: 0.6923 - val_loss: 1.1165 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 691us/step - loss: 1.0752 - acc: 0.6154 - val_loss: 1.1177 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0739 - acc: 0.6154 - val_loss: 1.1188 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0725 - acc: 0.6923 - val_loss: 1.1200 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 228us/step - loss: 1.0712 - acc: 0.6923 - val_loss: 1.1211 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 537us/step - loss: 1.0698 - acc: 0.6923 - val_loss: 1.1222 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0685 - acc: 0.6923 - val_loss: 1.1233 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 228us/step - loss: 1.0672 - acc: 0.6923 - val_loss: 1.1244 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 691us/step - loss: 1.0658 - acc: 0.6923 - val_loss: 1.1254 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0644 - acc: 0.6923 - val_loss: 1.1265 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0630 - acc: 0.6154 - val_loss: 1.1275 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 229us/step - loss: 1.0617 - acc: 0.6923 - val_loss: 1.1286 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0603 - acc: 0.6923 - val_loss: 1.1297 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0589 - acc: 0.7692 - val_loss: 1.1307 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 386us/step - loss: 1.0574 - acc: 0.7692 - val_loss: 1.1318 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0560 - acc: 0.7692 - val_loss: 1.1329 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0545 - acc: 0.7692 - val_loss: 1.1339 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0531 - acc: 0.8462 - val_loss: 1.1349 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0516 - acc: 0.7692 - val_loss: 1.1358 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0500 - acc: 0.7692 - val_loss: 1.1368 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 154us/step - loss: 1.0485 - acc: 0.7692 - val_loss: 1.1378 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 997us/step - loss: 1.0469 - acc: 0.7692 - val_loss: 1.1388 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0453 - acc: 0.8462 - val_loss: 1.1398 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 230us/step - loss: 1.0437 - acc: 0.9231 - val_loss: 1.1407 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0421 - acc: 0.9231 - val_loss: 1.1417 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 153us/step - loss: 1.0405 - acc: 0.9231 - val_loss: 1.1427 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 77us/step - loss: 1.0389 - acc: 0.9231 - val_loss: 1.1436 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 155us/step - loss: 1.0372 - acc: 0.9231 - val_loss: 1.1445 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(42, 5, input_length=5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, \n",
    "                activation='relu'))\n",
    "model.add(Dense(3, \n",
    "                activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(padded_sent, \n",
    "                    df.label, \n",
    "                    epochs=50, \n",
    "                    verbose=1, \n",
    "                    validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(padded_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 채팅에 예측사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning, I hope you are well today. What can I do for you?\n",
      "\n",
      "Human: End\n",
      "Bye! come back again soon.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "a = ''\n",
    "print('Good morning, I hope you are well today. What can I do for you?\\n')\n",
    "while ('End' not in a):\n",
    "    a = input('Human: ')\n",
    "    encoded_a = [one_hot(a, vocab_size)]\n",
    "    padded_a = pad_sequences(encoded_a, maxlen=5, padding='post')\n",
    "    pred_a = model.predict_classes(padded_a)\n",
    "    if pred_a == 0:\n",
    "        print(random.choice(greeting_response))        \n",
    "    elif pred_a == 1:\n",
    "        print(random.choice(goodbye_response))\n",
    "    elif pred_a == 2:\n",
    "        print(random.choice(thanks_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDING EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1,1,1,1,1,0,0,0,0,0]) #1점이 긍정, 0점 부정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding (50 vocab size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 45],\n",
       " [23, 4],\n",
       " [1, 8],\n",
       " [8, 4],\n",
       " [9],\n",
       " [38],\n",
       " [35, 8],\n",
       " [10, 23],\n",
       " [35, 4],\n",
       " [1, 20, 45, 15]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "encoded_doc = [one_hot(d, 50) for d in docs]\n",
    "encoded_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding (4 maxlen, post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 45,  0,  0],\n",
       "       [23,  4,  0,  0],\n",
       "       [ 1,  8,  0,  0],\n",
       "       [ 8,  4,  0,  0],\n",
       "       [ 9,  0,  0,  0],\n",
       "       [38,  0,  0,  0],\n",
       "       [35,  8,  0,  0],\n",
       "       [10, 23,  0,  0],\n",
       "       [35,  4,  0,  0],\n",
       "       [ 1, 20, 45, 15]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_doc = pad_sequences(encoded_doc, maxlen=4, padding='post')\n",
    "padded_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6947 - acc: 0.3750 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6931 - acc: 0.3750 - val_loss: 0.6945 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 250us/step - loss: 0.6915 - acc: 0.3750 - val_loss: 0.6959 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6899 - acc: 0.6250 - val_loss: 0.6972 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 372us/step - loss: 0.6883 - acc: 0.7500 - val_loss: 0.6986 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6867 - acc: 0.7500 - val_loss: 0.7000 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 125us/step - loss: 0.6852 - acc: 0.7500 - val_loss: 0.7014 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 251us/step - loss: 0.6836 - acc: 0.7500 - val_loss: 0.7027 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 372us/step - loss: 0.6820 - acc: 0.7500 - val_loss: 0.7041 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 247us/step - loss: 0.6804 - acc: 0.7500 - val_loss: 0.7055 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6788 - acc: 0.7500 - val_loss: 0.7069 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6772 - acc: 0.7500 - val_loss: 0.7083 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6756 - acc: 0.7500 - val_loss: 0.7097 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6741 - acc: 0.7500 - val_loss: 0.7112 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6725 - acc: 0.7500 - val_loss: 0.7126 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6709 - acc: 0.7500 - val_loss: 0.7140 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6693 - acc: 0.7500 - val_loss: 0.7155 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 125us/step - loss: 0.6677 - acc: 0.7500 - val_loss: 0.7169 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 375us/step - loss: 0.6660 - acc: 0.7500 - val_loss: 0.7184 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 501us/step - loss: 0.6644 - acc: 0.7500 - val_loss: 0.7198 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 126us/step - loss: 0.6628 - acc: 0.7500 - val_loss: 0.7213 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 499us/step - loss: 0.6612 - acc: 0.7500 - val_loss: 0.7228 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6595 - acc: 0.7500 - val_loss: 0.7243 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 370us/step - loss: 0.6579 - acc: 0.7500 - val_loss: 0.7258 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 499us/step - loss: 0.6562 - acc: 0.7500 - val_loss: 0.7273 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 251us/step - loss: 0.6546 - acc: 0.7500 - val_loss: 0.7288 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 247us/step - loss: 0.6529 - acc: 0.7500 - val_loss: 0.7303 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6512 - acc: 0.7500 - val_loss: 0.7319 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 499us/step - loss: 0.6495 - acc: 0.8750 - val_loss: 0.7335 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6478 - acc: 0.7500 - val_loss: 0.7350 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6462 - acc: 0.7500 - val_loss: 0.7366 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 251us/step - loss: 0.6444 - acc: 0.7500 - val_loss: 0.7382 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 372us/step - loss: 0.6427 - acc: 0.7500 - val_loss: 0.7398 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 250us/step - loss: 0.6410 - acc: 0.7500 - val_loss: 0.7415 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 503us/step - loss: 0.6392 - acc: 0.7500 - val_loss: 0.7431 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 501us/step - loss: 0.6375 - acc: 0.7500 - val_loss: 0.7448 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 253us/step - loss: 0.6357 - acc: 0.7500 - val_loss: 0.7464 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6340 - acc: 0.7500 - val_loss: 0.7481 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 373us/step - loss: 0.6322 - acc: 0.7500 - val_loss: 0.7498 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6304 - acc: 0.7500 - val_loss: 0.7516 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 246us/step - loss: 0.6286 - acc: 0.7500 - val_loss: 0.7533 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6268 - acc: 0.7500 - val_loss: 0.7550 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6250 - acc: 0.7500 - val_loss: 0.7568 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6232 - acc: 0.7500 - val_loss: 0.7586 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 252us/step - loss: 0.6213 - acc: 0.7500 - val_loss: 0.7604 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6195 - acc: 0.7500 - val_loss: 0.7622 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.6176 - acc: 0.7500 - val_loss: 0.7641 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6158 - acc: 0.7500 - val_loss: 0.7659 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 375us/step - loss: 0.6139 - acc: 0.7500 - val_loss: 0.7678 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 249us/step - loss: 0.6120 - acc: 0.7500 - val_loss: 0.7697 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(50, 8, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(padded_doc, \n",
    "                    labels, \n",
    "                    epochs=50, \n",
    "                    validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(padded_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "10/10 [==============================] - 0s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.642020583152771, 0.6000000238418579]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_doc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b56c238c8>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
